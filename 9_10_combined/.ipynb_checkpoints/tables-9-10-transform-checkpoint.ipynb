{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from databaker.framework import *\n",
    "from databakerUtils.writers import v4Writer\n",
    "import glob, math\n",
    "from databakerUtils.api import getAllCodes, getAllLabels\n",
    "\n",
    "timeOfData = '2018'\n",
    "\n",
    "locationTable9 = 'table_9/' + timeOfData + '/*'\n",
    "locationTable10 = 'table_10/' + timeOfData + '/*'\n",
    "output_file = 'v4_ashe_table_9and10_' + timeOfData + '.csv'\n",
    "\n",
    "#all files in location\n",
    "allFiles9 = glob.glob(locationTable9)\n",
    "allFiles10 = glob.glob(locationTable10)\n",
    "allFiles = allFiles9 + allFiles10\n",
    "\n",
    "#ignoring any files that are not ashe files and ignoring gender pay gap file\n",
    "allFiles = [file for file in allFiles if '.12' not in file]\n",
    "\n",
    "#separate data and CV interval data\n",
    "files = [file for file in allFiles if not file.endswith('CV.xls')]\n",
    "filesCV = [file for file in allFiles if file.endswith('CV.xls')]\n",
    "\n",
    "#making sure both lists are in the same order\n",
    "files = sorted(files)\n",
    "filesCV = sorted(filesCV)\n",
    "\n",
    "#loading in all tabs for data\n",
    "allTabs = []\n",
    "for file in files:\n",
    "    readFile = loadxlstabs(file)\n",
    "    allTabs.append(readFile)\n",
    "\n",
    "#loading in all tabs for CV interval data\n",
    "allTabsCV = []\n",
    "for file in filesCV:\n",
    "    readFile = loadxlstabs(file)\n",
    "    allTabsCV.append(readFile)\n",
    "    \n",
    "#above process creates a list of lists\n",
    "#need to flatten the lists    \n",
    "flatList = [item for subitem in allTabs for item in subitem]\n",
    "flatListCV = [item for subitem in allTabsCV for item in subitem]\n",
    "\n",
    "#removing the info tabs from each spreadsheet\n",
    "tabs = [tab for tab in flatList if tab.name != 'Notes']\n",
    "tabsCV = [tab for tab in flatListCV if tab.name != 'CV notes']\n",
    "\n",
    "#quick check to make sure number of files or number of tabs hasn't changed\n",
    "if len(tabs) == len(tabsCV) != len(files)*9:\n",
    "    raise Exception('Number of files or number of tabs has changed')\n",
    "\n",
    "'''will be iterating the databaking process'''\n",
    "#max number of rows out of all the sheets\n",
    "maxLength = []\n",
    "for tab in tabs:\n",
    "    tabMax = len(tab.excel_ref('A'))\n",
    "    maxLength.append(tabMax)\n",
    "maxLength = max(maxLength)\n",
    "batchNumber = 20    #iterates over this many rows at a time\n",
    "numberOfIterations = math.ceil(maxLength/batchNumber)   #databaking will iterate this many times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Functions'''\n",
    "\n",
    "def pconGeography(value):\n",
    "    '''\n",
    "    Changes some of the geography codes to match the admin codes\n",
    "    (top levels weren't included in geography hierarchy provided)\n",
    "    '''\n",
    "    lookup = {\n",
    "            'E12000001':'E15000001',\n",
    "            'E12000002':'E15000002',\n",
    "            'E12000003':'E15000003',\n",
    "            'E12000004':'E15000004',\n",
    "            'E12000005':'E15000005',\n",
    "            'E12000006':'E15000006',\n",
    "            'E12000007':'E15000007',\n",
    "            'E12000008':'E15000008',\n",
    "            'E12000009':'E15000009'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "def renameGeog(value):\n",
    "    '''\n",
    "    geography label of \"East\" is used in dataset but \"Eastern\" used in codelist\n",
    "    '''\n",
    "    lookup = {\n",
    "            'East':'Eastern'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "#pull in codelist for sheetName (ashe-earnings)\n",
    "sheetNameURL = 'https://api.beta.ons.gov.uk/v1/code-lists/ashe-earnings/editions/one-off/codes'\n",
    "dataSheetNameCodes = getAllCodes(sheetNameURL)\n",
    "dataSheetNameLabels = getAllLabels(sheetNameURL)\n",
    "sheetNameDict = dict(zip(dataSheetNameLabels,dataSheetNameCodes))\n",
    "\n",
    "def sheetNameLookup(value):\n",
    "    '''returns ashe-earnings labels from sheetName'''\n",
    "    value = '.'+value.split('.')[1]\n",
    "    lookup = {\n",
    "            '.1a':'Weekly pay - Gross',\n",
    "            '.2a':'Weekly pay - Excluding overtime',\n",
    "            '.3a':'Basic pay - Including other pay',\n",
    "            '.4a':'Overtime pay',\n",
    "            '.5a':'Hourly pay - Gross',\n",
    "            '.6a':'Hourly pay - Excluding overtime',\n",
    "            '.7a':'Annual pay - Gross',\n",
    "            '.8a':'Annual pay - Incentive',\n",
    "            '.9a':'Paid hours worked - Total',\n",
    "            '.10a':'Paid hours worked - Basic',\n",
    "            '.11a':'Paid hours worked - Overtime'\n",
    "            }\n",
    "    return lookup[value]\n",
    "\n",
    "def sheetNameCodeLookup(value):\n",
    "    '''returns ashe-earnings codes from labels'''\n",
    "    return sheetNameDict.get(value,value.lower().replace(' - ','-').replace(' ','-'))\n",
    "\n",
    "def tableNumberLookup(value):\n",
    "    lookup = {\n",
    "            '9':'Workplace',\n",
    "            '10':'Residence'\n",
    "            }\n",
    "    return lookup[value]\n",
    "\n",
    "\n",
    "#pull in codelist for 'variable' (ashe-statistics)\n",
    "variableURL = 'https://api.beta.ons.gov.uk/v1/code-lists/ashe-statistics/editions/one-off/codes'\n",
    "dataVariableCodes = getAllCodes(variableURL)\n",
    "dataVariableLabels = getAllLabels(variableURL)\n",
    "variableDict = dict(zip(dataVariableLabels,dataVariableCodes))\n",
    "\n",
    "def variableTypeCodeLookup(value):\n",
    "    '''returns ashe-statistics code from label'''\n",
    "    return variableDict.get(value,value)\n",
    "\n",
    "def variableType(value):\n",
    "    #one of these lookups needs removing\n",
    "    '''returns variable labels in a more useable format (string) also matches labels'''\n",
    "    lookup = {\n",
    "            '10.0':'10th percentile', \n",
    "            '20.0':'20th percentile', \n",
    "            '25.0':'25th percentile', \n",
    "            '30.0':'30th percentile',\n",
    "            '40.0':'40th percentile', \n",
    "            '60.0':'60th percentile', \n",
    "            '70.0':'70th percentile', \n",
    "            '75.0':'75th percentile', \n",
    "            '80.0':'80th percentile', \n",
    "            '90.0':'90th percentile'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "#splitting tabName into sex and working pattern\n",
    "\n",
    "def sexLabels(value):\n",
    "    '''returns ashe-sex labels from tabName'''\n",
    "    lookup = {\n",
    "            'Full-Time':'All', \n",
    "            'Part-Time':'All',\n",
    "            'Male Full-Time':'Male', \n",
    "            'Male Part-Time':'Male', \n",
    "            'Female Full-Time':'Female',\n",
    "            'Female Part-Time':'Female'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "def sexCodes(value):\n",
    "    '''returns ashe-sex codes from labels'''\n",
    "    return value.lower()\n",
    "\n",
    "def workingPatternLabels(value):\n",
    "    '''returns working patterns labels from tabName'''\n",
    "    lookup = {\n",
    "            'Male':'All', \n",
    "            'Female':'All',\n",
    "            'Male Full-Time':'Full-Time', \n",
    "            'Male Part-Time':'Part-Time', \n",
    "            'Female Full-Time':'Full-Time',\n",
    "            'Female Part-Time':'Part-Time'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "def workingPatternCodes(value):\n",
    "    '''returns working pattern codes from labels'''\n",
    "    return value.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DataBaking'''\n",
    "print('DataBaking...')\n",
    "conversionsegments = []\n",
    "\n",
    "for i in range(0,numberOfIterations):\n",
    "\n",
    "    Min = str(6 + batchNumber * i)  #data starts on row 6\n",
    "    Max = str(int(Min) + batchNumber - 1)\n",
    "\n",
    "    for tab in tabs:\n",
    "        \n",
    "        #columns are named badly\n",
    "        #quick check to make sure they haven't changed\n",
    "        if tab.excel_ref('C5').value != '(thousand)':\n",
    "            raise Exception(\"Column names aren't right\")\n",
    "            \n",
    "        if tab.excel_ref('S7').value != 'Key':\n",
    "            raise Exception('Key has moved')\n",
    "            \n",
    "        key = tab.excel_ref('S7').expand(RIGHT).expand(DOWN)    #referenced but not used\n",
    "        junk = tab.excel_ref('A').filter(contains_string('Northern Ireland')).shift(DOWN).expand(DOWN)\n",
    "        \n",
    "        geographyNames = tab.excel_ref('A'+Min+':A'+Max).is_not_blank().is_not_whitespace() - junk\n",
    "        geographyCodes = tab.excel_ref('B'+Min+':B'+Max).is_not_blank().is_not_whitespace()\n",
    "        \n",
    "        #ignoring the annual percentage change and number of jobs\n",
    "        columnsToIgnore = tab.excel_ref('E') | tab.excel_ref('G') | tab.excel_ref('C')\n",
    "        variable = tab.excel_ref('C5').expand(RIGHT).is_not_blank().is_not_whitespace() - columnsToIgnore\n",
    "        \n",
    "        tabName = tab.name\n",
    "        \n",
    "        sheetName = tab.excel_ref('a1').value.split(' ')[1]\n",
    "    \n",
    "        tableNumber = sheetName.split('.')[0]\n",
    "    \n",
    "        obs = variable.waffle(geographyNames)\n",
    "        \n",
    "        dimensions = [\n",
    "                HDimConst(TIME, timeOfData),\n",
    "                HDim(geographyCodes, GEOG, DIRECTLY, LEFT),\n",
    "                HDim(geographyNames, 'GeogNames', DIRECTLY, LEFT),\n",
    "                HDim(variable, 'Variable', DIRECTLY, ABOVE),\n",
    "                HDimConst('tabName', tabName),\n",
    "                HDimConst('sheetName', sheetName),\n",
    "                HDimConst('tableNumber', tableNumber)\n",
    "                ]\n",
    "        \n",
    "        if len(obs) != 0:\n",
    "            #only use ConversionSegment if there is data\n",
    "            conversionsegment = ConversionSegment(tab, dimensions, obs).topandas()\n",
    "            conversionsegments.append(conversionsegment)\n",
    "        \n",
    "    if (int(Max)-1)%10 == 0:\n",
    "        #return a message after every round (iteration number)\n",
    "        print('Round {} out of {} done.. rows between {} and {}'.format(i+1,numberOfIterations,Min,Max))\n",
    "        \n",
    "    \n",
    "data = pd.concat(conversionsegments)\n",
    "df = v4Writer(output_file,data,asFrame=True)\n",
    "\n",
    "firstTime = str(datetime.datetime.now() - startTime)\n",
    "print(\"Time taken: \" + firstTime) \n",
    " \n",
    "'''DataBaking CV interval data'''\n",
    "print('DataBaking the CV intervals...')\n",
    "\n",
    "conversionsegments = []\n",
    "\n",
    "for i in range(0,numberOfIterations):\n",
    "\n",
    "    Min = str(6 + batchNumber * i)  #data starts on row 6\n",
    "    Max = str(int(Min) + batchNumber - 1)\n",
    "  \n",
    "    for tab in tabsCV:\n",
    "        \n",
    "        #columns are named badly\n",
    "        #quick check to make sure they haven't changed\n",
    "        if tab.excel_ref('C5').value != '(thousand)':\n",
    "            raise Exception(\"Column names aren't right\")\n",
    "            \n",
    "        if tab.excel_ref('S7').value != 'Key':\n",
    "            raise Exception('Key has moved')\n",
    "            \n",
    "        key = tab.excel_ref('S7').expand(RIGHT).expand(DOWN)    \n",
    "        junk = tab.excel_ref('A').filter(contains_string('Northern Ireland')).shift(DOWN).expand(DOWN)\n",
    "        \n",
    "        geographyNames = tab.excel_ref('A'+Min+':A'+Max).is_not_blank().is_not_whitespace() - junk\n",
    "        geographyCodes = tab.excel_ref('B'+Min+':B'+Max).is_not_blank().is_not_whitespace()\n",
    "        \n",
    "        #ignoring the annual percentage change and number of jobs\n",
    "        columnsToIgnore = tab.excel_ref('E') | tab.excel_ref('G') | tab.excel_ref('C')\n",
    "        variable = tab.excel_ref('C5').expand(RIGHT).is_not_blank().is_not_whitespace() - columnsToIgnore\n",
    "        \n",
    "        tabName = tab.name\n",
    "        \n",
    "        sheetName = tab.excel_ref('a1').value.split(' ')[1]\n",
    "    \n",
    "        tableNumber = sheetName.split('.')[0]\n",
    "    \n",
    "        obs = variable.waffle(geographyNames)\n",
    "        \n",
    "        dimensions = [\n",
    "                HDimConst(TIME, timeOfData),\n",
    "                HDim(geographyCodes, GEOG, DIRECTLY, LEFT),\n",
    "                HDim(geographyNames, 'GeogNames', DIRECTLY, LEFT),\n",
    "                HDim(variable, 'Variable', DIRECTLY, ABOVE),\n",
    "                HDimConst('tabName', tabName),\n",
    "                HDimConst('sheetName', sheetName),\n",
    "                HDimConst('tableNumber', tableNumber)\n",
    "                ]\n",
    "        \n",
    "        if len(obs) != 0:\n",
    "            #only use ConversionSegment if there is data\n",
    "            conversionsegment = ConversionSegment(tab, dimensions, obs).topandas()\n",
    "            conversionsegments.append(conversionsegment)\n",
    "        \n",
    "    if (int(Max)-1)%10 == 0:\n",
    "        #return a message after every round (iteration number)\n",
    "        print('Round {} out of {} done.. rows between {} and {}'.format(i+1,numberOfIterations,Min,Max))\n",
    "        \n",
    "dataCV = pd.concat(conversionsegments)\n",
    "dfCV = v4Writer(output_file,dataCV,asFrame=True) \n",
    "\n",
    "#quick check to make sure data and CV data is same length\n",
    "if len(df.index) != len(dfCV.index):\n",
    "    raise Exception('Data and CV interval data lengths don\\'t match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Post processing'''\n",
    "\n",
    "#V4 column for dfCV is the CV intervals for data\n",
    "df['CV'] = dfCV['V4_1']\n",
    "\n",
    "df['Time_codelist'] = df['Time']\n",
    "df['Geography'] = df['GeogNames']\n",
    "df = df.drop(['GeogNames', 'GeogNames_codelist'], axis = 1)\n",
    "\n",
    "#renaming columns\n",
    "colsRename = {\n",
    "        'V4_1':'V4_2',\n",
    "        'Time':'time',\n",
    "        'Time_codelist':'calendar-years',\n",
    "        'Geography':'geography',\n",
    "        'Geography_codelist':'parliamentary-geography',\n",
    "        'Variable':'statistics',\n",
    "        'Variable_codelist':'ashe-statistics',\n",
    "        'sheetName':'hoursandearnings',\n",
    "        'sheetName_codelist':'ashe-hours-and-earnings',\n",
    "        'tableNumber':'workplaceorresidence',\n",
    "        'tableNumber_codelist':'ashe-workplace-or-residence'\n",
    "        }\n",
    "\n",
    "df['Geography'] = df['Geography'].apply(lambda x:x.strip())\n",
    "df['Geography'] = df['Geography'].apply(renameGeog)\n",
    "df['Geography_codelist'] = df['Geography_codelist'].apply(pconGeography)\n",
    "\n",
    "df['sheetName'] = df['sheetName'].apply(sheetNameLookup)\n",
    "df['sheetName_codelist'] = df['sheetName'].apply(sheetNameCodeLookup)\n",
    "df['sheetName_codelist'] = df['sheetName_codelist'].apply(lambda x:x.replace(' ','-'))\n",
    "\n",
    "df['tableNumber'] = df['tableNumber'].apply(tableNumberLookup)\n",
    "df['tableNumber_codelist'] = df['tableNumber'].apply(lambda x:x.lower())\n",
    "\n",
    "df['Variable'] = df['Variable'].apply(variableType)\n",
    "df['Variable_codelist'] = df['Variable'].apply(variableTypeCodeLookup)\n",
    "\n",
    "df['tabName_codelist'] = df['tabName'].apply(lambda x:x.lower().replace('-','_'))\n",
    "\n",
    "df['sex'] = df['tabName'].apply(sexLabels)\n",
    "df['ashe-sex'] = df['sex'].apply(sexCodes)\n",
    "\n",
    "df['workingpattern'] = df['tabName'].apply(workingPatternLabels)\n",
    "df['ashe-working-pattern'] =df['workingpattern'].apply(workingPatternCodes)\n",
    "\n",
    "#reordering columns\n",
    "df = df[['V4_1', 'Data_Marking', 'CV', 'Time_codelist', 'Time',\n",
    "         'Geography_codelist', 'Geography', 'Variable_codelist', 'Variable',\n",
    "         'ashe-sex', 'sex', 'ashe-working-pattern', 'workingpattern', \n",
    "         'sheetName_codelist', 'sheetName', 'tableNumber_codelist', 'tableNumber']]\n",
    "\n",
    "df = df.rename(columns = colsRename)\n",
    "\n",
    "#data markers for CV's need to be filled in\n",
    "df.loc[df['CV'] == '','CV'] = 'x'\n",
    "\n",
    "df.to_csv(output_file, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
