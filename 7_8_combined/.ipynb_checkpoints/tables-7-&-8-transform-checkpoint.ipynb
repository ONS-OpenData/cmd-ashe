{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from databaker.framework import *\n",
    "from databakerUtils.writers import v4Writer\n",
    "import glob, math, requests\n",
    "from databakerUtils.api import getAllCodes, getAllLabels\n",
    "\n",
    "timeOfData = '2018'     #Change to match the year of the data\n",
    "\n",
    "locationTable7 = 'table_7/*'\n",
    "locationTable8 = 'table_8/*'\n",
    "output_file = 'v4_ashe_table_7and8_' + timeOfData + '.csv'\n",
    "\n",
    "#all files in location\n",
    "allFiles7 = glob.glob(locationTable7)\n",
    "allFiles8 = glob.glob(locationTable8)\n",
    "\n",
    "#ignoring any files that are not ashe files and ignoring gender pay gap file\n",
    "allFiles7 = [file for file in allFiles7 if file.startswith(locationTable7[:-1]+'PROV')]\n",
    "allFiles7 = [file for file in allFiles7 if '7.12' not in file]\n",
    "\n",
    "allFiles8 = [file for file in allFiles8 if file.startswith(locationTable8[:-1]+'PROV')]\n",
    "allFiles8 = [file for file in allFiles8 if '8.12' not in file]\n",
    "\n",
    "allFiles = allFiles7 + allFiles8\n",
    "\n",
    "#separate data and CV interval data\n",
    "files = [file for file in allFiles if not file.endswith('CV.xls')]\n",
    "filesCV = [file for file in allFiles if file.endswith('CV.xls')]\n",
    "\n",
    "#organises both lists into the same order\n",
    "files = sorted(files)\n",
    "filesCV = sorted(filesCV)\n",
    "\n",
    "#loading in all tabs for data\n",
    "allTabs = []\n",
    "for file in files:\n",
    "    readFile = loadxlstabs(file)\n",
    "    allTabs.append(readFile)\n",
    "\n",
    "#loading in all tabs for CV interval data\n",
    "allTabsCV = []\n",
    "for file in filesCV:\n",
    "    readFile = loadxlstabs(file)\n",
    "    allTabsCV.append(readFile)\n",
    "\n",
    "#above process creates a list of lists\n",
    "#need to flatten the lists    \n",
    "flatList = [item for subitem in allTabs for item in subitem]\n",
    "flatListCV = [item for subitem in allTabsCV for item in subitem]\n",
    "\n",
    "#ignoring the info tabs from each spreadsheet\n",
    "tabs = [tab for tab in flatList if tab.name != 'Notes']\n",
    "tabsCV = [tab for tab in flatListCV if tab.name != 'CV notes']\n",
    "   \n",
    "#quick check to make sure number of files or number of tabs hasn't changed\n",
    "if len(tabs) == len(tabsCV) != len(files)*9:\n",
    "    raise Exception('Number of files or number of tabs has changed')\n",
    "\n",
    "'''will be iterating the databaking process'''\n",
    "#max number of rows out of all the sheets\n",
    "maxLength = []\n",
    "for tab in tabs:\n",
    "    tabMax = len(tab.excel_ref('A'))\n",
    "    maxLength.append(tabMax)\n",
    "maxLength = max(maxLength)\n",
    "batchNumber = 10    #iterates over this many rows at a time\n",
    "numberOfIterations = math.ceil(maxLength/batchNumber)   #databaking will iterate this many times\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Fucntions'''\n",
    "\n",
    "#pull in admin geography codelist from api\n",
    "adminURL = 'https://api.cmd-dev.onsdigital.co.uk/v1/code-lists/admin-geography/editions/one-off/codes'\n",
    "r = requests.get(adminURL)\n",
    "wholeDict = r.json()\n",
    "geogLookupDict = {}\n",
    "for item in wholeDict['items']:\n",
    "    geogLookupDict.update({item['id']:item['label']})\n",
    "def geogLabelLookup(value):\n",
    "    return geogLookupDict[value]\n",
    "\n",
    "#pull in codelist for sheetName (ashe-earnings)\n",
    "sheetNameURL = 'https://api.beta.ons.gov.uk/v1/code-lists/ashe-earnings/editions/one-off/codes'\n",
    "dataSheetNameCodes = getAllCodes(sheetNameURL)\n",
    "dataSheetNameLabels = getAllLabels(sheetNameURL)\n",
    "sheetNameDict = dict(zip(dataSheetNameLabels,dataSheetNameCodes))\n",
    "\n",
    "def sheetNameLookup(value):\n",
    "    '''returns ashe-earnings labels from sheetName'''\n",
    "    value = '.'+value.split('.')[1]\n",
    "    lookup = {\n",
    "            '.1a':'Weekly pay - Gross',\n",
    "            '.2a':'Weekly pay - Excluding overtime',\n",
    "            '.3a':'Basic pay - Including other pay',\n",
    "            '.4a':'Overtime pay',\n",
    "            '.5a':'Hourly pay - Gross',\n",
    "            '.6a':'Hourly pay - Excluding overtime',\n",
    "            '.7a':'Annual pay - Gross',\n",
    "            '.8a':'Annual pay - Incentive',\n",
    "            '.9a':'Paid hours worked - Total',\n",
    "            '.10a':'Paid hours worked - Basic',\n",
    "            '.11a':'Paid hours worked - Overtime'\n",
    "            }\n",
    "    return lookup[value]\n",
    "\n",
    "def sheetNameCodeLookup(value):\n",
    "    '''returns ashe-earnings codes from labels'''\n",
    "    return sheetNameDict.get(value,value.lower().replace(' - ','-').replace(' ','-'))\n",
    "\n",
    "def tableNumberLookup(value):\n",
    "    lookup = {\n",
    "            '7':'Workplace',\n",
    "            '8':'Residence'\n",
    "            }\n",
    "    return lookup[value]\n",
    "\n",
    "#pull in codelist for 'variable' (ashe-statistics)\n",
    "variableURL = 'https://api.beta.ons.gov.uk/v1/code-lists/ashe-statistics/editions/one-off/codes'\n",
    "dataVariableCodes = getAllCodes(variableURL)\n",
    "dataVariableLabels = getAllLabels(variableURL)\n",
    "variableDict = dict(zip(dataVariableLabels,dataVariableCodes))\n",
    "\n",
    "def variableTypeCodeLookup(value):\n",
    "    '''returns ashe-statistics code from label'''\n",
    "    return variableDict.get(value,value)\n",
    "\n",
    "def variableType(value):\n",
    "    '''returns variable labels in a more useable format (string) also matches labels'''\n",
    "    lookup = {\n",
    "            '10.0':'10th percentile', \n",
    "            '20.0':'20th percentile', \n",
    "            '25.0':'25th percentile', \n",
    "            '30.0':'30th percentile',\n",
    "            '40.0':'40th percentile', \n",
    "            '60.0':'60th percentile', \n",
    "            '70.0':'70th percentile', \n",
    "            '75.0':'75th percentile', \n",
    "            '80.0':'80th percentile', \n",
    "            '90.0':'90th percentile',\n",
    "            '(thousand)':'Number of jobs'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "#splitting tabName into sex and working pattern\n",
    "\n",
    "def sexLabels(value):\n",
    "    '''returns ashe-sex labels from tabName'''\n",
    "    lookup = {\n",
    "            'Full-Time':'All', \n",
    "            'Part-Time':'All',\n",
    "            'Male Full-Time':'Male', \n",
    "            'Male Part-Time':'Male', \n",
    "            'Female Full-Time':'Female',\n",
    "            'Female Part-Time':'Female'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "def sexCodes(value):\n",
    "    '''returns ashe-sex codes from labels'''\n",
    "    return value.lower()\n",
    "\n",
    "def workingPatternLabels(value):\n",
    "    '''returns working patterns labels from tabName'''\n",
    "    lookup = {\n",
    "            'Male':'All', \n",
    "            'Female':'All',\n",
    "            'Male Full-Time':'Full-Time', \n",
    "            'Male Part-Time':'Part-Time', \n",
    "            'Female Full-Time':'Full-Time',\n",
    "            'Female Part-Time':'Part-Time'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "def workingPatternCodes(value):\n",
    "    '''returns working pattern codes from labels'''\n",
    "    return value.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Databaking'''\n",
    "print('Databaking...')\n",
    "conversionsegments = []\n",
    "\n",
    "for i in range(0,numberOfIterations):\n",
    "\n",
    "    Min = str(6 + batchNumber * i)  #data starts on row 6\n",
    "    Max = str(int(Min) + batchNumber - 1) \n",
    "\n",
    "    for tab in tabs:\n",
    "        \n",
    "        #columns are named badly\n",
    "        #quick check to make sure they haven't changed\n",
    "        if tab.excel_ref('C5').value != '(thousand)':\n",
    "            raise Exception(\"Column names aren't right - {}\".format(tab.name))\n",
    "            \n",
    "        if tab.excel_ref('S7').value != 'Key':\n",
    "            raise Exception('Key has moved - {}'.format(tab.name))\n",
    "            \n",
    "        #key = tab.excel_ref('S7').expand(RIGHT).expand(DOWN)    #referenced but not used (waffle)\n",
    "        junk = tab.excel_ref('A').filter(contains_string('Not Classified')).shift(DOWN).expand(DOWN)\n",
    "        \n",
    "        geographyNames = tab.excel_ref('A'+Min+':A'+Max).is_not_blank().is_not_whitespace() - junk\n",
    "        geographyCodes = tab.excel_ref('B'+Min+':B'+Max).is_not_blank().is_not_whitespace()\n",
    "        \n",
    "        #ignoring the annual percentage change and number of jobs\n",
    "        columnsToIgnore = tab.excel_ref('E') | tab.excel_ref('G') | tab.excel_ref('C')\n",
    "        variable = tab.excel_ref('C5').expand(RIGHT).is_not_blank().is_not_whitespace() - columnsToIgnore\n",
    "        \n",
    "        tabName = tab.name\n",
    "        \n",
    "        sheetName = tab.excel_ref('a1').value.split(' ')[1]\n",
    "    \n",
    "        tableNumber = sheetName.split('.')[0]\n",
    "    \n",
    "        obs = variable.waffle(geographyNames)   #waffle used incase gaps in data\n",
    "        \n",
    "        dimensions = [\n",
    "                HDimConst(TIME, timeOfData),\n",
    "                HDim(geographyCodes,GEOG,DIRECTLY,LEFT),\n",
    "                HDim(geographyNames,'GeogNames',DIRECTLY,LEFT),\n",
    "                HDim(variable,'Variable',DIRECTLY,ABOVE),\n",
    "                HDimConst('tabName',tabName),\n",
    "                HDimConst('sheetName',sheetName),\n",
    "                HDimConst('tableNumber',tableNumber)\n",
    "                ]\n",
    "        \n",
    "        if len(obs) != 0:\n",
    "            #only use ConversionSegment if there is data\n",
    "            conversionsegment = ConversionSegment(tab,dimensions,obs).topandas()\n",
    "            conversionsegments.append(conversionsegment)\n",
    "        \n",
    "    if (int(Max)-1)%10 == 0:\n",
    "        #return a message after every round (iteration number)\n",
    "        print('Round {} out of {} done.. rows between {} and {}'.format(i+1,numberOfIterations,Min,Max))\n",
    "        \n",
    "    \n",
    "data = pd.concat(conversionsegments)\n",
    "df = v4Writer(output_file,data, asFrame=True) \n",
    " \n",
    "\n",
    "'''databaking CV interval data'''\n",
    "#same process as above\n",
    "print('Databaking the CV intervals...')\n",
    "\n",
    "conversionsegments = []\n",
    "  \n",
    "for i in range(0, numberOfIterations):\n",
    "\n",
    "    Min = str(6 + batchNumber * i)\n",
    "    Max = str(int(Min) + batchNumber - 1) \n",
    "\n",
    "    for tab in tabsCV:\n",
    "        \n",
    "        #columns are named badly\n",
    "        #quick check to make sure they haven't changed\n",
    "        if tab.excel_ref('C5').value != '(thousand)':\n",
    "            raise Exception(\"Column names aren't right - {}\".format(tab.name))\n",
    "            \n",
    "        if tab.excel_ref('S7').value != 'Key':\n",
    "            raise Exception('Key has moved - {}'.format(tab.name))\n",
    "            \n",
    "        #key = tab.excel_ref('S7').expand(RIGHT).expand(DOWN)    #referenced but not used (waffle)\n",
    "        junk = tab.excel_ref('A').filter(contains_string('Not Classified')).shift(DOWN).expand(DOWN)\n",
    "        \n",
    "        geographyNames = tab.excel_ref('A'+Min+':A'+Max).is_not_blank().is_not_whitespace() - junk\n",
    "        geographyCodes = tab.excel_ref('B'+Min+':B'+Max).is_not_blank().is_not_whitespace()\n",
    "        \n",
    "        #ignoring the annual percentage change and number of jobs\n",
    "        columnsToIgnore = tab.excel_ref('E') | tab.excel_ref('G') | tab.excel_ref('C')\n",
    "        variable = tab.excel_ref('C5').expand(RIGHT).is_not_blank().is_not_whitespace() - columnsToIgnore\n",
    "        \n",
    "        tabName = tab.name\n",
    "        \n",
    "        sheetName = tab.excel_ref('a1').value.split(' ')[1]\n",
    "    \n",
    "        tableNumber = sheetName.split('.')[0]\n",
    "    \n",
    "        obs = variable.waffle(geographyNames)   #waffle used incase gaps in data\n",
    "        \n",
    "        dimensions = [\n",
    "                HDimConst(TIME, timeOfData),\n",
    "                HDim(geographyCodes,GEOG,DIRECTLY,LEFT),\n",
    "                HDim(geographyNames,'GeogNames',DIRECTLY,LEFT),\n",
    "                HDim(variable,'Variable',DIRECTLY,ABOVE),\n",
    "                HDimConst('tabName',tabName),\n",
    "                HDimConst('sheetName',sheetName),\n",
    "                HDimConst('tableNumber',tableNumber)\n",
    "                ]\n",
    "        \n",
    "        if len(obs) != 0:\n",
    "            conversionsegment = ConversionSegment(tab,dimensions,obs).topandas()\n",
    "            conversionsegments.append(conversionsegment)\n",
    "        \n",
    "    if (int(Max)-1)%10 == 0:\n",
    "        print('Round {} out of {} done.. rows between {} and {}'.format(i+1,numberOfIterations,Min,Max))\n",
    "        \n",
    "        \n",
    "dataCV = pd.concat(conversionsegments)\n",
    "dfCV = v4Writer(output_file,dataCV,asFrame=True)\n",
    "\n",
    "#quick check to make sure data and CV data is same length\n",
    "if len(df.index) != len(dfCV.index):\n",
    "    raise Exception('Data and CV interval data lengths don\\'t match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Post processing'''\n",
    "\n",
    "#V4 column for dfCV is the CV intervals for data\n",
    "df['CV'] = dfCV[dfCV.columns[0]]\n",
    "\n",
    "df['Time_codelist'] = df['Time']\n",
    "df['Geography'] = df['GeogNames']\n",
    "df = df.drop(['GeogNames','GeogNames_codelist'],axis=1)\n",
    "\n",
    "#renaming columns\n",
    "colsRename = {\n",
    "        'V4_1':'V4_2',\n",
    "        'Time':'time',\n",
    "        'Time_codelist':'calendar-years',\n",
    "        'Geography':'geography',\n",
    "        'Geography_codelist':'admin-geography',\n",
    "        'Variable':'statistics',\n",
    "        'Variable_codelist':'ashe-statistics',\n",
    "        'sheetName':'hoursandearnings',\n",
    "        'sheetName_codelist':'ashe-hours-and-earnings',\n",
    "        'tableNumber':'workplaceorresidence',\n",
    "        'tableNumber_codelist':'ashe-workplace-or-residence'\n",
    "        }\n",
    "\n",
    "#sorting geography\n",
    "df.loc[df['Geography'] == 'Not Classified', 'Geography_codelist'] = 'not-classified'\n",
    "df['Geography'] = df['Geography_codelist'].apply(geogLabelLookup)\n",
    "\n",
    "'''applying functions'''\n",
    "\n",
    "df['sheetName'] = df['sheetName'].apply(sheetNameLookup)\n",
    "df['sheetName_codelist'] = df['sheetName'].apply(sheetNameCodeLookup)\n",
    "df['sheetName_codelist'] = df['sheetName_codelist'].apply(lambda x:x.replace(' ','-'))\n",
    "\n",
    "df['tableNumber'] = df['tableNumber'].apply(tableNumberLookup)\n",
    "df['tableNumber_codelist'] = df['tableNumber'].apply(lambda x:x.lower())\n",
    "\n",
    "df['Variable'] = df['Variable'].apply(variableType)\n",
    "df['Variable_codelist'] = df['Variable'].apply(variableTypeCodeLookup)\n",
    "\n",
    "df['tabName_codelist'] = df['tabName'].apply(lambda x:x.lower().replace('-','_'))\n",
    "\n",
    "df['sex'] = df['tabName'].apply(sexLabels)\n",
    "df['ashe-sex'] = df['sex'].apply(sexCodes)\n",
    "\n",
    "df['workingpattern'] = df['tabName'].apply(workingPatternLabels)\n",
    "df['ashe-working-pattern'] =df['workingpattern'].apply(workingPatternCodes)\n",
    "\n",
    "#reordering columns\n",
    "df = df[['V4_1', 'Data_Marking', 'CV', 'Time_codelist', 'Time',\n",
    "         'Geography_codelist', 'Geography', 'Variable_codelist', 'Variable',\n",
    "         'ashe-sex', 'sex', 'ashe-working-pattern', 'workingpattern', \n",
    "         'sheetName_codelist', 'sheetName', 'tableNumber_codelist', 'tableNumber']]\n",
    "\n",
    "df = df.rename(columns = colsRename)\n",
    "\n",
    "#data markers for CV's need to be filled in\n",
    "df.loc[df['CV'] == '','CV'] = 'x'\n",
    "\n",
    "df.to_csv(output_file, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
