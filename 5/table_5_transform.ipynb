{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Created on Mon Oct 29 2//018 15:29:33\n",
    "\n",
    "@author: robgrant\n",
    "\"\"\"\n",
    "'''\n",
    "Takes around 45 mins to run\n",
    "Have split tabName into sex and working pattern\n",
    "number of jobs column has been excluded\n",
    "change input file in geogLabelLookup when codelist is uploaded\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from databaker.framework import *\n",
    "from databakerUtils.writers import v4Writer\n",
    "import glob\n",
    "from databakerUtils.api import getAllCodes, getAllLabels\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import requests\n",
    "\n",
    "\n",
    "locationTable5_2018 = 'table_5/*'\n",
    "output_file = 'v4_ashe_table_5_2018.csv'\n",
    "current_year = '2018'\n",
    "\n",
    "#all files in location\n",
    "allFiles5_2018 = glob.glob(locationTable5_2018)\n",
    "\n",
    "\n",
    "allFiles = allFiles5_2018\n",
    "\n",
    "#separate data and CV interval data\n",
    "files = [file for file in allFiles if not file.endswith('CV.xls')]\n",
    "filesCV = [file for file in allFiles if file.endswith('CV.xls')]\n",
    "\n",
    "files = sorted(files)\n",
    "filesCV = sorted(filesCV)\n",
    "\n",
    "#loading in all tabs for data\n",
    "allTabs = []\n",
    "for file in files:\n",
    "    readFile = loadxlstabs(file)\n",
    "    allTabs.append(readFile)\n",
    "\n",
    "#loading in all tabs for CV interval data\n",
    "allTabsCV = []\n",
    "for file in filesCV:\n",
    "    readFile = loadxlstabs(file)\n",
    "    allTabsCV.append(readFile)\n",
    "\n",
    "#above process creates a list of lists\n",
    "#need to flatten the lists    \n",
    "flatList = [item for subitem in allTabs for item in subitem]\n",
    "flatListCV = [item for subitem in allTabsCV for item in subitem]\n",
    "\n",
    "#removing the info tabs from each spreadsheet\n",
    "tabs = [tab for tab in flatList if tab.name != 'Notes']\n",
    "tabsCV = [tab for tab in flatListCV if tab.name != 'CV notes']\n",
    "   \n",
    "#quick check to make sure number of files or number of tabs hasn't changed\n",
    "if len(tabs) == len(tabsCV) != len(files)*9:\n",
    "    raise Exception('Number of files or number of tabs has changed')\n",
    "\n",
    "\n",
    "maxLength = max(len(tabs[1].excel_ref('A')),len(tabs[0].excel_ref('A')))\n",
    "batchNumber = 34\n",
    "numberOfIterations = math.ceil(maxLength/batchNumber)\n",
    "regions = ['NORTH EAST','NORTH WEST','EAST MIDLANDS','WEST MIDLANDS','YORKSHIRE AND THE HUMBER','EAST','LONDON','SOUTH EAST','SOUTH WEST','ENGLAND','WALES','SCOTLAND','NORTHERN IRELAND','ENGLAND AND WALES','GREAT BRITAIN','UNITED KINGDOM']\n",
    "region_codes = ['K02000001','K03000001','K04000001','E92000001','E12000001','E12000002','E12000003','E12000004','E12000005','E12000006','E12000007','E12000008','E12000009','W92000004','S92000003','N92000002']\n",
    "\n",
    "\n",
    "'''databaking data'''\n",
    "print('Databaking...')\n",
    "conversionsegments = []\n",
    "\n",
    "\n",
    "for i in range(0,numberOfIterations):    \n",
    "\n",
    "    Min = str(6+batchNumber*i)\n",
    "    Max = str(39+batchNumber*i)\n",
    "    \n",
    "\n",
    "    for tab in tabs:\n",
    "        \n",
    "        #columns are named badly\n",
    "        #quick check to make sure they haven't changed\n",
    "        if tab.excel_ref('C5').value != '(thousand)':\n",
    "            raise Exception(\"Column names aren't right\")\n",
    "            \n",
    "        if tab.excel_ref('S7').value != 'Key':\n",
    "            raise Exception('Key has moved')\n",
    "            \n",
    "        key = tab.excel_ref('S7').expand(RIGHT).expand(DOWN)    #referenced but not used (waffle)\n",
    "        junk = tab.excel_ref('A').filter(contains_string('a  Employees')).expand(DOWN)\n",
    "        \n",
    "        geographyNames = tab.excel_ref('A'+Min+':A'+Max) - junk \n",
    "        geographyCodes = tab.excel_ref('B'+Min+':B'+Max)\n",
    "        \n",
    "            \n",
    "        #ignoring the annual percentage change and number of jobs\n",
    "        columnsToIgnore = tab.excel_ref('E') | tab.excel_ref('G') | tab.excel_ref('C')\n",
    "        variable = tab.excel_ref('C5').expand(RIGHT).is_not_blank().is_not_whitespace() - columnsToIgnore \n",
    "        \n",
    "        tabName = tab.name\n",
    "        \n",
    "        sheetName = tab.excel_ref('a1').value.split(' ')[2]\n",
    "    \n",
    "        tableNumber = sheetName.split('.')[0]\n",
    "    \n",
    "        obs = tab.excel_ref('D'+Min+':D'+Max).expand(RIGHT) - junk - columnsToIgnore - key  #waffle used incase gaps in data\n",
    "       \n",
    "        \n",
    "    \n",
    "        dimensions = [\n",
    "                HDimConst(TIME,current_year),\n",
    "                HDim(geographyCodes,GEOG,DIRECTLY,LEFT),\n",
    "                HDim(geographyNames,'GeogNames',DIRECTLY,LEFT),\n",
    "                HDim(variable,'Variable',DIRECTLY,ABOVE),\n",
    "                HDimConst('tabName',tabName),\n",
    "                HDimConst('sheetName',sheetName),\n",
    "                HDimConst('tableNumber',tableNumber)\n",
    "                ]\n",
    "        \n",
    "        \n",
    "        if len(obs) != 0:\n",
    "           conversionsegment = ConversionSegment(tab,dimensions,obs).topandas()\n",
    "           \n",
    "          \n",
    "            \n",
    "        conversionsegments.append(conversionsegment)\n",
    "       \n",
    "        if tabName == 'Female Part-Time':\n",
    "            print('{} is done'.format(sheetName))\n",
    "            \n",
    "        \n",
    "    \n",
    "data = pd.concat(conversionsegments)\n",
    "\n",
    "#remove nulls\n",
    "data = data[data.GeogNames.notnull()]\n",
    "data = data[data.Variable.notnull()]\n",
    "\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "data['region'] = ''\n",
    "\n",
    "data['GeogNames'] = data['GeogNames'].str.strip()\n",
    "data['GeogNamesOriginal'] = data['GeogNames']\n",
    "data['region'] = data['region'].str.upper()\n",
    "data['GeogNames'] = data['GeogNames'].str.replace('All ', ', All ')\n",
    "data['GeogNames'] = data['GeogNames'].str.replace('ALL ', ', ALL ')      \n",
    "data['GeogNames'] = data['GeogNames'].str.replace(' , , ', ', ')\n",
    "data['GeogNames'] = data['GeogNames'].str.replace(', , ', ', ')\n",
    "data['GeogNames'] = data['GeogNames'].str.replace(',, ', ', ')\n",
    "data['GeogNames'].loc[data['GeogNames'].isnull()] = 'None'\n",
    "\n",
    "#split region faster\n",
    "f = lambda x: x[\"GeogNames\"].split(\", \")[0]\n",
    "data['region'] = data.apply(f, axis=1)\n",
    "\n",
    "\n",
    "data['region'] = data['region'].str.strip()\n",
    "data['region'] = data['region'].str.upper()\n",
    "\n",
    "#change regions that weren't back to UK  \n",
    "data.loc[~data['region'].isin(regions), 'region'] = 'UNITED KINGDOM'\n",
    "\n",
    "#remove wrong ONS codes from SIC code\n",
    "data.loc[data[GEOG].isin(region_codes), GEOG] = ''\n",
    "\n",
    "#set up industry\n",
    "data['industry'] = ''\n",
    "\n",
    "#change GeogNames to upper\n",
    "data['GeogNames'] = data['GeogNames'].str.upper()\n",
    "\n",
    "#get industry from GeogNames by splitting against region\n",
    "g = lambda x: x['GeogNames'].replace(x['region'],'')\n",
    "data['industry'] = data.apply(g, axis=1)\n",
    "\n",
    "data['industry'] = data['industry'].str.replace(', ALL','ALL')\n",
    "data['industry'] = data['industry'].str.replace(',  ','ALL')\n",
    "  \n",
    "\n",
    "#remove commas by getting first few rows\n",
    "data['industry'] = data['industry'].str.strip()\n",
    "data['first'] = data['industry'].astype(str).str[0]\n",
    "\n",
    "\n",
    "#remove first comma if applicable\n",
    "data['industry']= data.apply(lambda x: x['industry'][2:] if x['first'] == ',' else x['industry'],axis=1)\n",
    "\n",
    "#convert to proper\n",
    "data['industry'] = data['industry'].str.title() \n",
    "data['region'] = data['region'].str.title()\n",
    "\n",
    "#tidying industries after proper\n",
    "data['industry'] = data['industry'].str.replace(' And ',' and ')\n",
    "data['industry'] = data['industry'].str.replace(' Of ',' of ')\n",
    "data['industry'] = data['industry'].str.replace(' With ',' with ')\n",
    "data['industry'] = data['industry'].str.replace(' Via ',' via ')\n",
    "data['region'] = data['region'].str.replace(' And ',' and ')\n",
    "data['industry'] = data['industry'].str.replace(', All ','ALL')\n",
    "\n",
    "#change back to all if it's a region\n",
    "data['industry2'] = data['industry'].str.upper()\n",
    "data['industry2']= data.apply(lambda x: 'All' if x['industry'] == '' else x['industry'],axis=1)\n",
    "\n",
    "#backup\n",
    "data2 = data.copy(deep = True)\n",
    "\n",
    "#remove unnecessary cols\n",
    "data = data.drop('first', 1)\n",
    "data = data.drop('GeogNamesOriginal', 1)\n",
    "data = data.drop('GeogNames', 1)\n",
    "data = data.drop('tableNumber', 1)\n",
    "\n",
    "#make df\n",
    "df = v4Writer(output_file,data,asFrame=True) \n",
    "\n",
    "\n",
    "'''databaking CV interval data'''\n",
    "print('Databaking the CV intervals...')\n",
    "\n",
    "conversionsegments = []\n",
    "  \n",
    "for i in range(0,numberOfIterations):    \n",
    "\n",
    "    Min = str(6+batchNumber*i)\n",
    "    Max = str(39+batchNumber*i)\n",
    "    \n",
    "    \n",
    "\n",
    "    for tab in tabsCV:\n",
    "        \n",
    "        #columns are named badly\n",
    "        #quick check to make sure they haven't changed\n",
    "        if tab.excel_ref('C5').value != '(thousand)':\n",
    "            raise Exception(\"Column names aren't right\")\n",
    "            \n",
    "        if tab.excel_ref('S7').value != 'Key':\n",
    "            raise Exception('Key has moved')\n",
    "            \n",
    "        key = tab.excel_ref('S7').expand(RIGHT).expand(DOWN)    #referenced but not used (waffle)\n",
    "        junk = tab.excel_ref('A').filter(contains_string('a  Employees')).expand(DOWN)\n",
    "        \n",
    "        geographyNames = tab.excel_ref('A'+Min+':A'+Max) - junk \n",
    "        geographyCodes = tab.excel_ref('B'+Min+':B'+Max)\n",
    "        \n",
    "            \n",
    "        #ignoring the annual percentage change and number of jobs\n",
    "        columnsToIgnore = tab.excel_ref('E') | tab.excel_ref('G') | tab.excel_ref('C')\n",
    "        variable = tab.excel_ref('C5').expand(RIGHT).is_not_blank().is_not_whitespace() - columnsToIgnore\n",
    "        \n",
    "        tabName = tab.name\n",
    "        \n",
    "        sheetName = tab.excel_ref('a1').value.split(' ')[2]\n",
    "    \n",
    "        tableNumber = sheetName.split('.')[0]\n",
    "    \n",
    "        obs = tab.excel_ref('D'+Min+':D'+Max).expand(RIGHT) - junk - columnsToIgnore - key  #waffle used incase gaps in data\n",
    "       \n",
    "        \n",
    "    \n",
    "        dimensions = [\n",
    "                HDimConst(TIME,current_year),\n",
    "                HDim(geographyCodes,GEOG,DIRECTLY,LEFT),\n",
    "                HDim(geographyNames,'GeogNames',DIRECTLY,LEFT),\n",
    "                HDim(variable,'Variable',DIRECTLY,ABOVE),\n",
    "                HDimConst('tabName',tabName),\n",
    "                HDimConst('sheetName',sheetName),\n",
    "                HDimConst('tableNumber',tableNumber)\n",
    "                ]\n",
    "        \n",
    "        \n",
    "        if len(obs) != 0:\n",
    "           conversionsegment = ConversionSegment(tab,dimensions,obs).topandas()\n",
    "           \n",
    "          \n",
    "            \n",
    "        conversionsegments.append(conversionsegment)\n",
    "       \n",
    "        if tabName == 'Female Part-Time':\n",
    "            print('{} is done'.format(sheetName))\n",
    "            \n",
    "        \n",
    "    \n",
    "dataCV = pd.concat(conversionsegments)\n",
    "dataCV = dataCV[dataCV.GeogNames.notnull()]\n",
    "dataCV = dataCV[dataCV.Variable.notnull()]\n",
    "dataCV = dataCV.reset_index(drop=True)\n",
    "dfCV = v4Writer(output_file,dataCV,asFrame=True) \n",
    "\n",
    "#quick check to make sure data and CV data is same length\n",
    "if len(df.index) != len(dfCV.index):\n",
    "    raise Exception('Data and CV interval data lengths don\\'t match')\n",
    "\n",
    "#V4 column for dfCV is the CV intervals for data\n",
    "df['CV'] = dfCV['V4_0']\n",
    "\n",
    "\n",
    "\n",
    "#more tidying\n",
    "df = df.drop('Geography',1)\n",
    "df['industry_codelist'] = df['Geography_codelist'].copy(deep = True)  \n",
    "df = df.drop('Geography_codelist',1)\n",
    "\n",
    "df2 = df.copy(deep = True)\n",
    "df = df2.copy(deep = True)\n",
    "\n",
    "\n",
    "#create codelist if all\n",
    "df['industry3'] = df['industry2'].copy().str.lower().str.replace(' ','-')\n",
    "df['industry_codelist']= df.apply(lambda x: x['industry3'] if x['industry_codelist'] == '' else x['industry_codelist'],axis=1)\n",
    "\n",
    "'''add in codelists'''\n",
    "\n",
    "adminURL = 'https://api.cmd-dev.onsdigital.co.uk/v1/code-lists/admin-geography/editions/one-off/codes'\n",
    "r = requests.get(adminURL)\n",
    "wholeDict = r.json()\n",
    "GeogDict = {}\n",
    "for item in wholeDict['items']:\n",
    "   GeogDict.update({item['label']:item['id']})\n",
    "\n",
    "\n",
    "def geogLabelLookup(value):\n",
    "    '''returns region codes'''\n",
    "    lookup = {\n",
    "            'North East':'E12000001',\n",
    "            'North West':'E12000002',\n",
    "            'Yorkshire and The Humber':'E12000003',\n",
    "            'East Midlands':'E12000004',\n",
    "            'West Midlands':'E12000005',\n",
    "            'East':'E12000006',\n",
    "            'London':'E12000007',\n",
    "            'South East':'E12000008',\n",
    "            'South West':'E12000009',\n",
    "            'England':'E92000001',\n",
    "            'Wales':'W92000004',\n",
    "            'Scotland':'S92000003',\n",
    "            'Northern Ireland':'N92000002',\n",
    "            'England and Wales':'K04000001',\n",
    "            'Great Britain':'K03000001',\n",
    "            'United Kingdom':'K02000001'\n",
    "            }\n",
    "    return lookup[value]\n",
    "\n",
    "#pull in codelist for sheetName (ashe-earnings)\n",
    "sheetNameURL = 'https://api.beta.ons.gov.uk/v1/code-lists/ashe-earnings/editions/one-off/codes'\n",
    "dataSheetNameCodes = getAllCodes(sheetNameURL)\n",
    "dataSheetNameLabels = getAllLabels(sheetNameURL)\n",
    "sheetNameDict = dict(zip(dataSheetNameLabels,dataSheetNameCodes))\n",
    "\n",
    "def sheetNameLookup(value):\n",
    "    '''returns ashe-earnings labels from sheetName'''\n",
    "    value = '.'+value.split('.')[1]\n",
    "    lookup = {\n",
    "            '.1a':'Weekly pay - Gross',\n",
    "            '.2a':'Weekly pay - Excluding overtime',\n",
    "            '.3a':'Basic pay - Including other pay',\n",
    "            '.4a':'Overtime pay',\n",
    "            '.5a':'Hourly pay - Gross',\n",
    "            '.6a':'Hourly pay - Excluding overtime',\n",
    "            '.7a':'Annual pay - Gross',\n",
    "            '.8a':'Annual pay - Incentive',\n",
    "            '.9a':'Paid hours worked - Total',\n",
    "            '.10a':'Paid hours worked - Basic',\n",
    "            '.11a':'Paid hours worked - Overtime'\n",
    "            }\n",
    "    return lookup[value]\n",
    "\n",
    "def sheetNameCodeLookup(value):\n",
    "    '''returns ashe-earnings codes from labels'''\n",
    "    return sheetNameDict.get(value,value.lower().replace(' - ','-').replace(' ','-'))\n",
    "\n",
    "\n",
    "#currently there is a codelist for 'variable' so will use it but will need changing/updating\n",
    "#pull in codelist for 'variable' (ashe-statistics)\n",
    "variableURL = 'https://api.beta.ons.gov.uk/v1/code-lists/ashe-statistics/editions/one-off/codes'\n",
    "dataVariableCodes = getAllCodes(variableURL)\n",
    "dataVariableLabels = getAllLabels(variableURL)\n",
    "variableDict = dict(zip(dataVariableLabels,dataVariableCodes))\n",
    "\n",
    "def variableTypeCodeLookup(value):\n",
    "    '''returns ashe-statistics code from label'''\n",
    "    return variableDict.get(value,value)\n",
    "\n",
    "def variableType(value):\n",
    "    #one of these lookups needs removing\n",
    "    '''returns variable labels in a more useable format (string) also matches labels'''\n",
    "    lookup = {\n",
    "            '(thousand)':'Number of jobs',\n",
    "            '10.0':'Percentile - 10',\n",
    "            '20.0':'Percentile - 20',\n",
    "            '25.0':'Percentile - 25',\n",
    "            '30.0':'Percentile - 30',\n",
    "            '40.0':'Percentile - 40',\n",
    "            '60.0':'Percentile - 60',\n",
    "            '70.0':'Percentile - 70',\n",
    "            '75.0':'Percentile - 75',\n",
    "            '80.0':'Percentile - 80',\n",
    "            '90.0':'Percentile - 90'\n",
    "            }\n",
    "    lookup2 = {\n",
    "            '10.0':'10', \n",
    "            '20.0':'20', \n",
    "            '25.0':'25', \n",
    "            '30.0':'30',\n",
    "            '40.0':'40', \n",
    "            '60.0':'60', \n",
    "            '70.0':'70', \n",
    "            '75.0':'75', \n",
    "            '80.0':'80', \n",
    "            '90.0':'90',\n",
    "            '(thousand)':'Number of jobs'\n",
    "            }\n",
    "    return lookup2.get(value,value)\n",
    "\n",
    "#splitting tabName into sex and working pattern\n",
    "\n",
    "def sexLabels(value):\n",
    "    '''returns ashe-sex labels from tabName'''\n",
    "    lookup = {\n",
    "            'Full-Time':'All', \n",
    "            'Part-Time':'All',\n",
    "            'Male Full-Time':'Male', \n",
    "            'Male Part-Time':'Male', \n",
    "            'Female Full-Time':'Female',\n",
    "            'Female Part-Time':'Female'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "def sexCodes(value):\n",
    "    '''returns ashe-sex codes from labels'''\n",
    "    return value.lower()\n",
    "\n",
    "def workingPatternLabels(value):\n",
    "    '''returns working patterns labels from tabName'''\n",
    "    lookup = {\n",
    "            'Male':'All', \n",
    "            'Female':'All',\n",
    "            'Male Full-Time':'Full-Time', \n",
    "            'Male Part-Time':'Part-Time', \n",
    "            'Female Full-Time':'Full-Time',\n",
    "            'Female Part-Time':'Part-Time'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "def workingPatternCodes(value):\n",
    "    '''returns working pattern codes from labels'''\n",
    "    return value.lower()\n",
    "\n",
    "#renaming columns\n",
    "colsRename = {\n",
    "        'V4_0':'V4_2',\n",
    "        'Time':'time',\n",
    "        'Time_codelist':'calendar-years',\n",
    "        'region':'geography',\n",
    "        'region_codelist':'admin-geography',\n",
    "        'Variable':'statistics',\n",
    "        'Variable_codelist':'ashe-statistics',\n",
    "        'sheetName':'hoursandearnings',\n",
    "        'sheetName_codelist':'ashe-hours-and-earnings',\n",
    "        'industry2':'standardindustrialclassification',\n",
    "        'industry_codelist':'sic'\n",
    "        }\n",
    "\n",
    "\n",
    "#sorting geography\n",
    "df['region_codelist'] = df['region'].apply(geogLabelLookup)\n",
    "\n",
    "\n",
    "'''applying functions'''\n",
    "\n",
    "df['sheetName'] = df['sheetName'].apply(sheetNameLookup)\n",
    "df['sheetName_codelist'] = df['sheetName'].apply(sheetNameCodeLookup)\n",
    "df['sheetName_codelist'] = df['sheetName_codelist'].apply(lambda x:x.replace(' ','-'))\n",
    "\n",
    "\n",
    "df['Variable'] = df['Variable'].apply(variableType)\n",
    "df['Variable_codelist'] = df['Variable'].apply(variableTypeCodeLookup)\n",
    "\n",
    "df['tabName_codelist'] = df['tabName'].apply(lambda x:x.lower())\n",
    "\n",
    "df['Time_codelist'] = df['Time']\n",
    "df = df.drop('industry',1)\n",
    "\n",
    "\n",
    "#get gender\n",
    "def sexLabels(value):\n",
    "    '''returns ashe-sex labels from tabName'''\n",
    "    lookup = {\n",
    "            'Full-Time':'All', \n",
    "            'Part-Time':'All',\n",
    "            'Male Full-Time':'Male', \n",
    "            'Male Part-Time':'Male', \n",
    "            'Female Full-Time':'Female',\n",
    "            'Female Part-Time':'Female'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "def sexCodes(value):\n",
    "    '''returns ashe-sex codes from labels'''\n",
    "    return value.lower()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#get working pattern\n",
    "    \n",
    "def workingPatternLabels(value):\n",
    "    '''returns working patterns labels from tabName'''\n",
    "    lookup = {\n",
    "            'Male':'All', \n",
    "            'Female':'All',\n",
    "            'Male Full-Time':'Full-Time', \n",
    "            'Male Part-Time':'Part-Time', \n",
    "            'Female Full-Time':'Full-Time',\n",
    "            'Female Part-Time':'Part-Time'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "def workingPatternCodes(value):\n",
    "    '''returns working pattern codes from labels'''\n",
    "    return value.lower()\n",
    "\n",
    "\n",
    "#change to percentiles\n",
    "def percentileChange(value):\n",
    "    #one of these lookups needs removing\n",
    "    '''matches percentiles'''\n",
    "    lookup = {\n",
    "            '10':'10th percentile',\n",
    "            '20':'20th percentile',\n",
    "            '25':'25th percentile',\n",
    "            '30':'30th percentile',\n",
    "            '40':'40th percentile',\n",
    "            '60':'60th percentile',\n",
    "            '70':'70th percentile',\n",
    "            '75':'75th percentile',\n",
    "            '80':'80th percentile',\n",
    "            '90':'90th percentile',\n",
    "            'Median':'Median',\n",
    "            'Mean':'Mean'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "#change industries\n",
    "    \n",
    "#leading zero first\n",
    "def leadingZero(value):\n",
    "    #one of these lookups needs removing\n",
    "    '''matches percentiles'''\n",
    "    lookup = {\n",
    "            '1':'01',\n",
    "            '2':'02',\n",
    "            '3':'03',\n",
    "            '4':'04',\n",
    "            '5':'05',\n",
    "            '6':'06',\n",
    "            '7':'07',\n",
    "            '8':'08',\n",
    "            '9':'09'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "\n",
    "def industryChange(value):\n",
    "    #one of these lookups needs removing\n",
    "    '''matches labels that need changing back'''\n",
    "    lookup = {\n",
    "            'all : All':'Total',\n",
    "            'all-manufacturing : All Manufacturing':'All Manufacturing',\n",
    "            'all-index-of-production-industries : All Index of Production Industries':'All Index of Production Industries',\n",
    "            'all-industries-and-services : All Industries and Services':'All Industries and Services',\n",
    "            'all-service-industries : All Service Industries':'All Service Industries'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "def industryLabelChange(value):\n",
    "    #one of these lookups needs removing\n",
    "    '''changes all'''\n",
    "    lookup = {\n",
    "            'all':'total'\n",
    "            }\n",
    "    return lookup.get(value,value)\n",
    "\n",
    "df['workingpattern'] = df['tabName'].apply(workingPatternLabels)\n",
    "df['ashe-working-pattern'] = df['workingpattern'].apply(industryChange).str.lower()\n",
    "\n",
    "df['sex'] = df['tabName'].apply(sexLabels)\n",
    "df['ashe-sex'] = df['sex'].apply(sexCodes)\n",
    "\n",
    "df3 = df.copy(deep = True)\n",
    "df = df3.copy(deep = True)\n",
    "\n",
    "\n",
    "#add code to label\n",
    "df['industry_codelist'] = df['industry_codelist'].apply(leadingZero)\n",
    "df['industry2'] = df['industry_codelist'] + ' : ' + df['industry2']\n",
    "df['industry2'] = df['industry2'].apply(industryChange)\n",
    "df['industry_codelist'] = df['industry_codelist'].apply(industryLabelChange)\n",
    "\n",
    "\n",
    "#reordering columns\n",
    "df = df[['V4_0', 'Data_Marking','CV','Time_codelist', 'Time',\n",
    "         'region_codelist','region','Variable_codelist','Variable',\n",
    "         'industry_codelist','industry2', \n",
    "         'sheetName_codelist','sheetName','ashe-sex','sex', 'ashe-working-pattern', 'workingpattern']]\n",
    "\n",
    "df = df.rename(columns = colsRename)\n",
    "df['statistics'] = df['statistics'].apply(percentileChange)\n",
    "\n",
    "#data markers for CV's need to be filled in\n",
    "df.loc[df['CV'] == '','CV'] = 'x'\n",
    "\n",
    "#find cases where both data marking and obs are NA\n",
    "\n",
    "df.loc[df['V4_2'] == '','Data_Marking'] = 'x'\n",
    "\n",
    "#print\n",
    "df.to_csv(output_file,index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
